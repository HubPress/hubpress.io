= Hope in the time of malaria

:published_at: 2015-02-16
:hp-tags: malaria
:hp-image: ../covers/noor_fig2.jpg


Whilst the public's interest was understandably piqued by the horrific scenes and rapid spread of the 2014 Ebola epidemic, an even deadlier killer continued to infect people across most of sub-Saharan Africa. _Plasmodium falciparum_, one of a number of related parasites that cause malaria, and which is transmitted to humans by mosquitoes, kills around 500,000, mostly young, people every year in sub-Saharan Africa. Despite concerted research effort and intervention measures, for every death, a thousand more Africans, roughly 500 million, continue to be at moderate to high risk of the disease.

However, the situation used to be much worse. During the 1990s malaria was troubling more and more people in Africa, and in spite of decades of research, malaria was infecting almost half a billion people annually, with up to a million of these cases ending in death. Dramatic action was needed, and so the World Health Organisation, World Bank, UNICEF, and the UNDP clubbed together to found the Roll Back Malaria initiative, with the explicit aim of halving the suffering caused by malaria by 2010. This led to a renewed research effort and investment into malaria research and control in Africa; but was it successful? To assess any initiative like this, one needs to provide some metric of how the burden of disease has changed over time. A recent study published by Mohammed Noor and colleagues in The Lancet attempted just this, by looking at how the likelihood of a person getting malaria in Africa changed between 2000 and 2010.

For any infectious disease to spread, it has to be transmitted from person to person, so understanding the amount of transmission helps us to understand the risk of disease. At any given place, the infectiousness of malaria depends on a number of things. Some of these affect the mosquito, such as climate or season, or whether or not you live in a city, but others are independent of this, such as the number of people around you who have malaria. Even in the most mosquito-friendly environment, if mosquitoes cannot feed on infected people, then they will not be able to pass on the disease.

With this in mind, the authors spent 8 years searching for almost any document that recorded the results of a health survey where people had been randomly assessed for the presence of malaria in their blood. Each of these surveys represents a snapshot of the amount of people with malaria – its prevalence – at a given time, in a given place. When you live in Africa, the constant bombardment of your body by malaria parasites means that over time you build up some immunity, which is part of the reason that malaria kills so many children, so a key consideration was to standardise these data to be comparable across the age ranges of the survey participants. For each of 47 African countries, information relevant to mosquito distribution, like climate and human settlement patterns, was combined with the prevalence data, to build a statistical model that was used to predict the proportion of the population with malaria, and then map this across Africa. The researchers were therefore able to take the number of people infected with malaria at different times, in different places, and predict the risk of malaria at any place in time. Concentrating on the years at the beginning and end of the Roll Back Malaria initiative, 2000 and 2010, they compared the predicted numbers of people at risk to assess how they had changed over the intervening period.

Encouragingly, malaria risk in general dropped substantially across Africa, with more than a quarter of Africa's population in 2010 living in areas with lower transmission than in 2000. However, neither the risk, nor its reduction, was uniform across Africa, with ten countries, mostly in Central and West Africa, continuing to harbour the majority of people at highest risk from malaria. So, while the risk has reduced, it has not been removed. Tempting as it is to use these results to show that malaria initiatives in Africa are working, it's important to note that this study did not try to link any specific control strategy to the reduction, although it is the essential first step in identifying such an association. Perhaps the most important consequence of the study is that it provides a benchmark by which inter-governmental bodies can track the changing risk of malaria in different countries and target areas in need of greater help, although more research is needed to unpick why transmission was reduced more in some areas than others. Nevertheless, this study is important in demonstrating that the burden of malaria in Africa is slowly changing for the better, and that, more generally, investment in infectious disease control is likely to both save lives and deliver hope.